{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "datasets = {\n",
    "\t\"student\" : {\n",
    "\t\t\"train_name\" : \"prep_data/student/student_grades.csv\",\n",
    "\t\t\"X_col\" : range(33),\n",
    "\t\t\"Y_col\" : [33],\n",
    "\t\t\"has_header\" : True,\n",
    "\t\t\"filetype\" : \"CSV\",\n",
    "\t\t\"encode_labels\" : False\n",
    "\t},\n",
    "\t\"contraceptive\" : {\n",
    "\t\t\"train_name\" : \"prep_data/contraceptive/contraceptive.csv\",\n",
    "\t\t\"X_col\" : range(9),\n",
    "\t\t\"Y_col\" : [9],\n",
    "\t\t\"has_header\" : True,\n",
    "\t\t\"filetype\" : \"CSV\",\n",
    "\t\t\"encode_labels\" : False\n",
    "\t},\n",
    "\t\"autism\" : {\n",
    "\t\t\"train_name\" : \"prep_data/Autism-Adult-Data/Autism-Adult-Data-preproc.csv\",\n",
    "\t\t\"X_col\" : range(20),\n",
    "\t\t\"Y_col\" : [20],\n",
    "\t\t\"has_header\" : True,\n",
    "\t\t\"filetype\" : \"CSV\",\n",
    "\t\t\"encode_labels\" : False\n",
    "\t},\n",
    "\t\"bankruptcy\" : {\n",
    "\t\t\"train_name\" : \"prep_data/bankruptcy/bankrupt.csv\",\n",
    "\t\t\"X_col\" : range(6),\n",
    "\t\t\"Y_col\" : [6],\n",
    "\t\t\"has_header\" : True,\n",
    "\t\t\"filetype\" : \"CSV\",\n",
    "\t\t\"encode_labels\" : False\n",
    "\t},\n",
    "\t\"breast_cancer\" : {\n",
    "\t\t\"train_name\" : \"prep_data/breast-cancer/breast-cancer-wisconsin.data\",\n",
    "\t\t\"X_col\" : range(9),\n",
    "\t\t\"Y_col\" : [9],\n",
    "\t\t\"has_header\" : True,\n",
    "\t\t\"filetype\" : \"CSV\",\n",
    "\t\t\"encode_labels\" : False\n",
    "\t},\n",
    "\t\"horse\" : {\n",
    "\t\t\"train_name\" : \"prep_data/horse-colic/horse-colic.data-preproc.csv\",\n",
    "\t\t\"X_col\" : range(22),\n",
    "\t\t\"Y_col\" : [22],\n",
    "\t\t\"has_header\" : True,\n",
    "\t\t\"filetype\" : \"CSV\",\n",
    "\t\t\"encode_labels\" : False\n",
    "\t},\n",
    "    \"hr\" : {\n",
    "\t\t\"train_name\" : \"prep_data/hr-analytics/HR_comma_sep.csv\",\n",
    "\t\t\"X_col\" : range(9),\n",
    "\t\t\"Y_col\" : [9],\n",
    "\t\t\"has_header\" : True,\n",
    "\t\t\"filetype\" : \"CSV\",\n",
    "\t\t\"encode_labels\" : False\n",
    "\t},\n",
    "\t\"english\" : {\n",
    "\t\t\"train_name\" : \"prep_data/teaching-english/tae.csv\",\n",
    "\t\t\"X_col\" : range(5),\n",
    "\t\t\"Y_col\" : [5],\n",
    "\t\t\"has_header\" : True,\n",
    "\t\t\"filetype\" : \"CSV\",\n",
    "\t\t\"encode_labels\" : False\n",
    "\t},\n",
    "\t\"phishing\" : {\n",
    "\t\t\"train_name\" : \"prep_data/website-phishing/PhishingData.csv\",\n",
    "\t\t\"X_col\" : range(9),\n",
    "\t\t\"Y_col\" : [9],\n",
    "\t\t\"has_header\" : True,\n",
    "\t\t\"filetype\" : \"CSV\",\n",
    "\t\t\"encode_labels\" : False\n",
    "\t},\n",
    "\t\"wine\" : {\n",
    "\t\t\"train_name\" : \"prep_data/wine-quality/winequality-red.csv\",\n",
    "\t\t\"X_col\" : range(11),\n",
    "\t\t\"Y_col\" : [11],\n",
    "\t\t\"has_header\" : True,\n",
    "\t\t\"filetype\" : \"CSV\",\n",
    "\t\t\"encode_labels\" : False\n",
    "\t},\n",
    "\t\"amazon\" : {\n",
    "\t\t\"train_name\" : \"prep_data/amazon/amzreviews.csv\",\n",
    "\t\t\"X_col\" : range(1,3093),\n",
    "\t\t\"Y_col\" : [3093],\n",
    "\t\t\"has_header\" : True,\n",
    "\t\t\"filetype\" : \"CSV\",\n",
    "\t\t\"encode_labels\" : False\n",
    "\t},\n",
    "\t\"congress\" : {\n",
    "\t\t\"train_name\" : \"prep_data/congress/congress_leave.csv\",\n",
    "\t\t\"X_col\" : range(1,17),\n",
    "\t\t\"Y_col\" : [17],\n",
    "\t\t\"has_header\" : True,\n",
    "\t\t\"filetype\" : \"CSV\",\n",
    "\t\t\"encode_labels\" : False\n",
    "\t},\n",
    "\t\"covertype\" : {\n",
    "\t\t\"train_name\" : \"prep_data/covertypes/covertype_scale.csv\",\n",
    "\t\t\"X_col\" : range(54),\n",
    "\t\t\"Y_col\" : [54],\n",
    "\t\t\"has_header\" : True,\n",
    "\t\t\"filetype\" : \"CSV\",\n",
    "\t\t\"encode_labels\" : False\n",
    "\t},\n",
    "\t\"kidney\" : {\n",
    "\t\t\"train_name\" : \"prep_data/kidney/kidney_colMeanMode.csv\",\n",
    "\t\t\"X_col\" : range(24),\n",
    "\t\t\"Y_col\" : [24],\n",
    "\t\t\"has_header\" : True,\n",
    "\t\t\"filetype\" : \"CSV\",\n",
    "\t\t\"encode_labels\" : False\n",
    "\t}\n",
    "}\n",
    "\n",
    "def read_dataset(dataset):\n",
    "    df = pd.read_csv('../'+dataset[\"train_name\"])\n",
    "    data_X = df.iloc[:, dataset[\"X_col\"]].copy()\n",
    "    data_y = df.iloc[:, dataset[\"Y_col\"]].copy()\n",
    "    assert(data_y.columns[0] == 'Class')\n",
    "    return data_X, data_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning parameters for student dataset\n",
      "[student]1/180\n",
      "[student]2/180\n",
      "[student]3/180\n",
      "[student]4/180\n",
      "[student]5/180\n",
      "[student]6/180\n",
      "[student]7/180\n",
      "[student]8/180\n",
      "[student]9/180\n",
      "[student]10/180\n",
      "[student]11/180\n",
      "[student]12/180\n",
      "Tuning parameters for contraceptive dataset\n",
      "[contraceptive]13/180\n",
      "[contraceptive]14/180\n",
      "[contraceptive]15/180\n",
      "[contraceptive]16/180\n",
      "[contraceptive]17/180\n",
      "[contraceptive]18/180\n",
      "[contraceptive]19/180\n",
      "[contraceptive]20/180\n",
      "[contraceptive]21/180\n",
      "[contraceptive]22/180\n",
      "[contraceptive]23/180\n",
      "[contraceptive]24/180\n",
      "Tuning parameters for autism dataset\n",
      "[autism]25/180\n",
      "[autism]26/180\n",
      "[autism]27/180\n",
      "[autism]28/180\n",
      "[autism]29/180\n",
      "[autism]30/180\n",
      "[autism]31/180\n",
      "[autism]32/180\n",
      "[autism]33/180\n",
      "[autism]34/180\n",
      "[autism]35/180\n",
      "[autism]36/180\n",
      "Tuning parameters for bankruptcy dataset\n",
      "[bankruptcy]37/180\n",
      "[bankruptcy]38/180\n",
      "[bankruptcy]39/180\n",
      "[bankruptcy]40/180\n",
      "[bankruptcy]41/180\n",
      "[bankruptcy]42/180\n",
      "[bankruptcy]43/180\n",
      "[bankruptcy]44/180\n",
      "[bankruptcy]45/180\n",
      "[bankruptcy]46/180\n",
      "[bankruptcy]47/180\n",
      "[bankruptcy]48/180\n",
      "Tuning parameters for breast_cancer dataset\n",
      "[breast_cancer]49/180\n",
      "[breast_cancer]50/180\n",
      "[breast_cancer]51/180\n",
      "[breast_cancer]52/180\n",
      "[breast_cancer]53/180\n",
      "[breast_cancer]54/180\n",
      "[breast_cancer]55/180\n",
      "[breast_cancer]56/180\n",
      "[breast_cancer]57/180\n",
      "[breast_cancer]58/180\n",
      "[breast_cancer]59/180\n",
      "[breast_cancer]60/180\n",
      "Tuning parameters for horse dataset\n",
      "[horse]61/180\n",
      "[horse]62/180\n",
      "[horse]63/180\n",
      "[horse]64/180\n",
      "[horse]65/180\n",
      "[horse]66/180\n",
      "[horse]67/180\n",
      "[horse]68/180\n",
      "[horse]69/180\n",
      "[horse]70/180\n",
      "[horse]71/180\n",
      "[horse]72/180\n",
      "Tuning parameters for hr dataset\n",
      "[hr]73/180\n",
      "[hr]74/180\n",
      "[hr]75/180\n",
      "[hr]76/180\n",
      "[hr]77/180\n",
      "[hr]78/180\n",
      "[hr]79/180\n",
      "[hr]80/180\n",
      "[hr]81/180\n",
      "[hr]82/180\n",
      "[hr]83/180\n",
      "[hr]84/180\n",
      "Tuning parameters for english dataset\n",
      "[english]85/180\n",
      "[english]86/180\n",
      "[english]87/180\n",
      "[english]88/180\n",
      "[english]89/180\n",
      "[english]90/180\n",
      "[english]91/180\n",
      "[english]92/180\n",
      "[english]93/180\n",
      "[english]94/180\n",
      "[english]95/180\n",
      "[english]96/180\n",
      "Tuning parameters for phishing dataset\n",
      "[phishing]97/180\n",
      "[phishing]98/180\n",
      "[phishing]99/180\n",
      "[phishing]100/180\n",
      "[phishing]101/180\n",
      "[phishing]102/180\n",
      "[phishing]103/180\n",
      "[phishing]104/180\n",
      "[phishing]105/180\n",
      "[phishing]106/180\n",
      "[phishing]107/180\n",
      "[phishing]108/180\n",
      "Tuning parameters for wine dataset\n",
      "[wine]109/180\n",
      "[wine]110/180\n",
      "[wine]111/180\n",
      "[wine]112/180\n",
      "[wine]113/180\n",
      "[wine]114/180\n",
      "[wine]115/180\n",
      "[wine]116/180\n",
      "[wine]117/180\n",
      "[wine]118/180\n",
      "[wine]119/180\n",
      "[wine]120/180\n",
      "Tuning parameters for amazon dataset\n",
      "[amazon]121/180\n",
      "[amazon]122/180\n",
      "[amazon]123/180\n",
      "[amazon]124/180\n",
      "[amazon]125/180\n",
      "[amazon]126/180\n",
      "[amazon]127/180\n",
      "[amazon]128/180\n",
      "[amazon]129/180\n",
      "[amazon]130/180\n",
      "[amazon]131/180\n",
      "[amazon]132/180\n",
      "Tuning parameters for congress dataset\n",
      "[congress]133/180\n",
      "[congress]134/180\n",
      "[congress]135/180\n",
      "[congress]136/180\n",
      "[congress]137/180\n",
      "[congress]138/180\n",
      "[congress]139/180\n",
      "[congress]140/180\n",
      "[congress]141/180\n",
      "[congress]142/180\n",
      "[congress]143/180\n",
      "[congress]144/180\n",
      "Tuning parameters for covertype dataset\n",
      "[covertype]145/180\n",
      "[covertype]146/180\n",
      "[covertype]147/180\n",
      "[covertype]148/180\n",
      "[covertype]149/180\n",
      "[covertype]150/180\n",
      "[covertype]151/180\n",
      "[covertype]152/180\n",
      "[covertype]153/180\n",
      "[covertype]154/180\n",
      "[covertype]155/180\n",
      "[covertype]156/180\n",
      "Tuning parameters for kidney dataset\n",
      "[kidney]157/180\n",
      "[kidney]158/180\n",
      "[kidney]159/180\n",
      "[kidney]160/180\n",
      "[kidney]161/180\n",
      "[kidney]162/180\n",
      "[kidney]163/180\n",
      "[kidney]164/180\n",
      "[kidney]165/180\n",
      "[kidney]166/180\n",
      "[kidney]167/180\n",
      "[kidney]168/180\n"
     ]
    }
   ],
   "source": [
    "header = \"model,dataset,scoring,p1,p2,acc\"\n",
    "output = \"../results/grid_search_res.csv\"\n",
    "#with open(output, \"a\") as f:\n",
    "#    f.write(header+'\\n')\n",
    "parameters = {'svm': {'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'], 'C': [1,10,100,1000]},\n",
    "              'rf': {'n_estimators': [10, 30, 50, 100], 'max_depth': [None,1,3]},\n",
    "              'knn': {'n_neighbors': [1,3,5,8,10,30,50,100], 'weights': ['uniform', 'distance']},\n",
    "              'mnb': {},\n",
    "              'mlp': {'activation': ['identity', 'relu', 'logistic'], 'alpha': [0.001, 1.0000000000000001e-05, 9.9999999999999995e-07]}}\n",
    "\n",
    "# Split the dataset 70/30\n",
    "total_iter = 14*4*3\n",
    "current_iter = 0\n",
    "for dataset in list(datasets.keys()):\n",
    "    print(\"Tuning parameters for %s dataset\" % dataset)\n",
    "    X, y = read_dataset(datasets[dataset])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=0)\n",
    "    y_train = np.ravel(y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "    scores = ['accuracy','precision_macro', 'recall_macro']\n",
    "    for label, model in {'svm': SVC(),'knn':KNeighborsClassifier(),'rf': RandomForestClassifier(), 'mlp': MLPClassifier()}.items():\n",
    "        for score in scores:\n",
    "            current_iter += 1\n",
    "            print(\"[%s]%d/%d\" % (dataset,current_iter, total_iter))\n",
    "            #print(\"# Tuning hyper-parameters for %s, model %s\" % (score, model.__class__.__name__))\n",
    "            #print()\n",
    "            clf = GridSearchCV(model, parameters[label], cv=5,scoring=('%s' % score))\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            #print(\"Best parameters set found on development set:\")\n",
    "            #print()\n",
    "            #print(clf.best_params_)\n",
    "            #print()\n",
    "            #print(\"Grid scores on development set:\")\n",
    "            #print()\n",
    "            means = clf.cv_results_['mean_test_score']\n",
    "            stds = clf.cv_results_['std_test_score']\n",
    "            #for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            #    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "            #print()\n",
    "\n",
    "            #print(\"Detailed classification report:\")\n",
    "            #print()\n",
    "            #print(\"The model is trained on the full development set.\")\n",
    "            #print(\"The scores are computed on the full evaluation set.\")\n",
    "            #print()\n",
    "            y_true, y_pred = y_test, clf.predict(X_test)\n",
    "            #print(classification_report(y_true, y_pred))\n",
    "            #print()\n",
    "            res_str = \"%s,%s,%s,%s,%s,%.2f\" % (model.__class__.__name__,\n",
    "                                                    dataset,\n",
    "                                                    score,\n",
    "                                                    list(clf.best_params_.values())[0],\n",
    "                                                    list(clf.best_params_.values())[1],\n",
    "                                                    (max(means)+accuracy_score(y_true, y_pred))/2)\n",
    "                                                        \n",
    "            #print(res_str)\n",
    "            with open(output, \"a\") as f:\n",
    "                f.write(res_str + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown, Latex, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter combinations by GridSearchCV for all classifiers. Sorted in order of accuracy.\n",
    "\"model,dataset,scoring,p1,p2,acc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">KNeighborsClassifier</th>\n",
       "      <th>1</th>\n",
       "      <th>uniform</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>distance</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>distance</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <th>distance</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>distance</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>distance</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">MLPClassifier</th>\n",
       "      <th>identity</th>\n",
       "      <th>0.001</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">logistic</th>\n",
       "      <th>0.001</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-05</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-06</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">relu</th>\n",
       "      <th>0.001</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-05</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-06</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">RandomForestClassifier</th>\n",
       "      <th>1</th>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>100</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">None</th>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">SVC</th>\n",
       "      <th>1</th>\n",
       "      <th>linear</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>linear</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">100</th>\n",
       "      <th>linear</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1000</th>\n",
       "      <th>poly</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_def = pd.read_csv('../results/grid_search_res.csv')\n",
    "res = df_def.drop(['dataset', 'scoring'], axis=1).groupby(['model','p1','p2']).count()\n",
    "display(HTML(res.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
